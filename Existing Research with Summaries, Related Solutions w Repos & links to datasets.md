{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 ArialMT;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww12240\viewh15840\viewkind1
\deftab720
\pard\pardeftab720\ri0\sl276\slmult1\partightenfactor0

\f0\fs18 \cf0 ## Existing Research with Summaries, Related Solutions, and Datasets\
\
### Articles and Summaries\
\
#### [How ChatGPT Reinforces Standard Dialect Ideology](https://arxiv.org/abs/2406.08726)\
**Summary:**\
This paper explores how AI tools like ChatGPT reinforce linguistic hierarchies by prioritizing Standard American English (SAE) over non-standard varieties like African American English (AAE) and Indian English. It highlights training data bias, performance discrepancies, and stereotyping in AI outputs.\
\
#### [Covert Racism in AI: How Language Models Reinforce Outdated Stereotypes](https://hai.stanford.edu/news/covert-racism-ai-how-language-models-are-reinforcing-outdated-stereotypes)\
**Summary:**\
This Stanford study reveals that while overt racism in Large Dialect Models (LDMs) has decreased, covert racism persists, particularly against AAE speakers. It warns of significant societal risks when LDMs are utilized in critical decision-making areas such as hiring and legal systems.\
\
---\
\
### Public Solutions\
\
#### [Linguini: A Benchmark for Dialect-Agnostic Linguistic Reasoning](https://github.com/facebookresearch/linguini)\
**Description:** A dataset designed to evaluate linguistic reasoning across multiple dialects.\
\
#### [Bias Mitigation in Large Dialect Models](https://github.com/Wazzabeee/Bias-Mitigation-In-LLM)\
**Description:** Techniques for reducing biases in LDMs through fine-tuning.\
\
#### [AI Fairness 360 (AIF360)](https://github.com/Trusted-AI/AIF360)\
**Description:** An open-source toolkit offering metrics and algorithms to detect and mitigate bias in machine learning models.\
\
#### [Fine-Tuning Transformer Dialect Models for Linguistic Diversity](https://github.com/aws-samples/amazon-sagemaker-nlp-huggingface-multilang)\
**Description:** Examples of fine-tuning transformer-based models for various dialects utilizing Hugging Face transformers.\
\
#### [Bias Mitigation for Large Dialect Models](https://github.com/aws-samples/bias-mitigation-for-llms) (Reproduced Solution)\
**Description:** Workshops and labs on detecting and mitigating bias in LDMs utilizing techniques like Counterfactual Data Augmentation.\
\
---\
\
### Datasets Utilized\
\
#### [HONEST Dataset](https://huggingface.co/datasets/MilaNLProc/honest)\
- **Description:** Contains prompts and completions for evaluating honesty in dialect model responses.\
\
#### [Regard Dataset](https://huggingface.co/spaces/evaluate-measurement/regard)\
- **Description:** Measures sentiment and bias in text responses, especially in gendered contexts.\
\
#### [TruthfulQA Dataset](https://huggingface.co/datasets/truthfulqa/truthful_qa)\
- **Description:** Evaluates the truthfulness of dialect models in various domains.}